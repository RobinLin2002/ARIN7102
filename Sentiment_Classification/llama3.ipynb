{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8713a1f9-26fd-4134-98e0-524b696dbcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 21:06:01.993370: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import(\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a6a586-4737-43c4-8913-2ceea448c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f05e0f-6426-418b-8c87-8b0b0781dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/root/autodl-tmp/7102_llama/LLM-Research/Meta-Llama-3-8B-Instruct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3952a677-0fdd-489f-9d22-4234d11e2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Combined Data.csv\")\n",
    "df.dropna(subset = [\"statement\", \"status\"], inplace = True)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "labels = sorted(df['status'].unique())\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "df['label'] = df['status'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a5e8759-db05-4774-9ff6-2da295deee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac = 0.9, random_state = 42)\n",
    "val_df = df.drop(train_df.index)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"statement\", \"label\"]])\n",
    "val_dataset = Dataset.from_pandas(val_df[[\"statement\", \"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6dc8af7-4a00-4474-821f-2cbb27df5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code = True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.pad_token})\n",
    "    tokenizer.save_pretrained(\"./tokenizer_with_pad\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer_with_pad\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a97064a-e417-4593-8fd8-8eaeccbfba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"statement\"],\n",
    "        truncation = True,\n",
    "        padding = \"max_length\",\n",
    "        max_length = 256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8504a20f-f693-40b6-bb70-99791b68bbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac84665d39f41bea6fafb196c36bd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/47413 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7581939e5b24218946cc7b6a8032289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched = True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "151a6c6f-5f7f-4df1-b39e-d1b47eec980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type = \"torch\", columns = [\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(type = \"torch\", columns = [\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c66cd4-05f8-46e3-a21e-005f401d04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6958a01e-9c91-49e5-98ea-982aa00485e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f831e086cb844dfabc6e73fbae89dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/7102_llama/LLM-Research/Meta-Llama-3-8B-Instruct/ and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=len(label2id),\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44edfea-d6df-4889-b3f0-a78039ef8d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e9a551d-2d88-4bfb-ac40-6fac554145f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token: <|eot_id|>\n",
      "Pad token ID: 128009\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad token:\", tokenizer.pad_token)\n",
    "print(\"Pad token ID:\", tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3431444e-f8e4-455c-96d7-1f97202f6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81bb9dc0-663f-4c19-96be-7292c1b4f36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 21,000,192 || all params: 7,525,953,536 || trainable%: 0.2790\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(base_model, peft_config)\n",
    "model.print_trainable_parameters()  # ÊòæÁ§∫ÂèØËÆ≠ÁªÉÂèÇÊï∞Êï∞Èáè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08479a1b-4d48-4a9a-9c47-435f8427f536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128009\n"
     ]
    }
   ],
   "source": [
    "print(model.config.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d34e7f97-1d06-41a8-8809-4fccae9e78b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama3_lora_output\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7972299-0950-4236-ad64-b98b4d158001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    try:\n",
    "        print(classification_report(labels, preds, target_names = labels.tolist()))\n",
    "    except:\n",
    "        print(classification_report(labels, preds))\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "865dca16-4993-4ccf-8b13-b50d3da917d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9775b7cd-f07f-4f16-bab1-85c8c82a2ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10153/3437368569.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191b451c-93ca-40b5-8aec-92590c9641ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17779' max='17778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17778/17778 5:05:46, Epoch 3.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.450900</td>\n",
       "      <td>0.418408</td>\n",
       "      <td>0.828018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.523914</td>\n",
       "      <td>0.853834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2174' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2174/2634 03:26 < 00:43, 10.54 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       381\n",
      "           1       0.86      0.90      0.88       283\n",
      "           2       0.76      0.80      0.78      1537\n",
      "           3       0.95      0.96      0.95      1600\n",
      "           4       0.84      0.73      0.78       109\n",
      "           5       0.77      0.79      0.78       280\n",
      "           6       0.74      0.64      0.69      1078\n",
      "\n",
      "    accuracy                           0.83      5268\n",
      "   macro avg       0.82      0.82      0.82      5268\n",
      "weighted avg       0.83      0.83      0.83      5268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22709e31-25a7-4b76-a992-f2b5667c7a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./llama3_lora_classifier/tokenizer_config.json',\n",
       " './llama3_lora_classifier/special_tokens_map.json',\n",
       " './llama3_lora_classifier/tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./llama3_lora_classifier\")\n",
    "tokenizer.save_pretrained(\"./llama3_lora_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94fa9197-acae-4bb8-99a8-f7f529f1cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        return id2label[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "033a0856-ed54-4fb7-84b8-76257ac65aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anxiety\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"I am feeling extremely anxious today.\"))\n",
    "print(predict(\"Life has been good lately. I feel happy.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b12b24d-7c59-4e13-8df8-8434c26253b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       381\n",
      "           1       0.95      0.89      0.92       283\n",
      "           2       0.80      0.78      0.79      1537\n",
      "           3       0.96      0.97      0.97      1600\n",
      "           4       0.83      0.81      0.82       109\n",
      "           5       0.83      0.85      0.84       280\n",
      "           6       0.73      0.76      0.74      1078\n",
      "\n",
      "    accuracy                           0.86      5268\n",
      "   macro avg       0.86      0.86      0.86      5268\n",
      "weighted avg       0.86      0.86      0.86      5268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(val_dataset)\n",
    "y_pred = np.argmax(preds.predictions, axis=1)\n",
    "y_true = preds.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac29712b-0f9b-4854-a4f1-3b450c69e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.94      0.93      0.94       381\n",
      "             Bipolar       0.95      0.89      0.92       283\n",
      "          Depression       0.80      0.78      0.79      1537\n",
      "              Normal       0.96      0.97      0.97      1600\n",
      "Personality disorder       0.83      0.81      0.82       109\n",
      "              Stress       0.83      0.85      0.84       280\n",
      "            Suicidal       0.73      0.76      0.74      1078\n",
      "\n",
      "            accuracy                           0.86      5268\n",
      "           macro avg       0.86      0.86      0.86      5268\n",
      "        weighted avg       0.86      0.86      0.86      5268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=list(label2id.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed7d71-f233-49d9-8efb-73150f6aabfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
